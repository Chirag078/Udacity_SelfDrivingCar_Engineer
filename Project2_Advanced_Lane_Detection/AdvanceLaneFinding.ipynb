{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "\n",
    "### goals \n",
    "   - Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "   - Apply a distortion correction to raw images.\n",
    "   - Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "   - Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "   - Detect lane pixels and fit to find the lane boundary.\n",
    "   - Determine the curvature of the lane and vehicle position with respect to center.\n",
    "   - Warp the detected lane boundaries back onto the original image.\n",
    "   - Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Functiion\n",
    "\n",
    " - Below Function is created Only for debuging purpose\n",
    "  1. SideBySide\n",
    "  2. Visulization\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SideBySide(img1,img2):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(24, 100))\n",
    "    \n",
    "    count = 0\n",
    "    for ax in axs:\n",
    "        if count == 0:\n",
    "            ax.imshow(img1)\n",
    "            count+=1\n",
    "        else:\n",
    "            ax.imshow(img2)\n",
    "            count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Visulization(out_black_img,leftx,lefty,rightx,righty,left_fitx,right_fitx,ploty):\n",
    "    out_black_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_black_img[righty, rightx] = [0, 255, 0]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    #plt.plot(left_fitx, ploty, color='orange')\n",
    "    #plt.plot(right_fitx, ploty, color='orange')\n",
    "    \n",
    "    return out_black_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding \n",
    "   - Fn - AbsSobelThresold : Applying Sobel\n",
    "   - Fn - MeanSobelThersold : Magnitude of gradiant\n",
    "   - Fn - ColorThresold : Color Thresholding \n",
    "   - Fn - Thresold : Mixed of all threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanSobelThersold(img,threshold=(0,255),sobel_kernel=3):\n",
    "    \n",
    "    # convert image from RGB to Gray\n",
    "    gray_img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)                                         \n",
    "    \n",
    "    # Using SobelX and SobelY calculate the meanSobel\n",
    "    sobelx = cv2.Sobel(gray_img,cv2.CV_64F,1,0,ksize=sobel_kernel)                          \n",
    "    sobely = cv2.Sobel(gray_img,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    abs_img = np.sqrt(sobelx**2 + sobely**2)  \n",
    "    scaler_img = np.uint8(255*(abs_img/np.max(abs_img)))\n",
    "    \n",
    "    # Create Grad_Binary\n",
    "    grad_binary = np.zeros_like(abs_img)\n",
    "    grad_binary[(scaler_img > threshold[0]) & (scaler_img < threshold[1])] = 1\n",
    "    return grad_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AbsSobelThresold(img,axis,threshold=(0,255),sobel_kernel=3):\n",
    "    \n",
    "    # convert image from RGB to Gray\n",
    "    gray_img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Use SobelX or SobelY \n",
    "    if axis == 'X':\n",
    "        sobel_img = cv2.Sobel(gray_img,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    if axis == 'Y':\n",
    "        sobel_img = cv2.Sobel(gray_img,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    \n",
    "    abs_img = np.absolute(sobel_img)\n",
    "    scaler_img = np.uint8(255*(abs_img/(np.max(abs_img))))\n",
    "    \n",
    "    # Create Grad_Binary\n",
    "    grad_binary = np.zeros_like(abs_img)\n",
    "    grad_binary[(scaler_img > threshold[0]) & (scaler_img < threshold[1])] = 1\n",
    "    return grad_binary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DirThreshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # convert image from RGB to Gray\n",
    "    gray_img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Take the gradient in x and y separately\n",
    "    sobel_x = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray_img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobel_x = np.absolute(sobel_x)\n",
    "    abs_sobel_y = np.absolute(sobel_y)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient\n",
    "    direction = np.arctan2(abs_sobel_y,abs_sobel_x)\n",
    "    direction = np.absolute(direction)\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    mask = np.zeros_like(direction)\n",
    "    mask[(direction >= thresh[0]) & (direction <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ColorThresold(img,threshold=(0,255)):\n",
    "    \n",
    "    # convert image from RGB to HLs Colorspace\n",
    "    hls_img = cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    # Extracting S_chennal\n",
    "    s_chennel = hls_img[:,:,2]\n",
    "    \n",
    "    # Appling Thresholding on S_Chennel of HLS\n",
    "    s_binary = np.zeros_like(s_chennel)\n",
    "    s_binary[(s_chennel > 50) & (s_chennel <= 255)] = 1  #150 255\n",
    "    \n",
    "    # Extracting R_chennel\n",
    "    r_chennel = img[:,:,0]\n",
    "    \n",
    "    # Appling Thresholding on R_Chennel of RGB\n",
    "    r_binary = np.zeros_like(r_chennel)\n",
    "    r_binary[(r_chennel > 150) & (r_chennel <= 255)] = 1\n",
    "    \n",
    "    # Extracting g_chennel\n",
    "    g_chennel = img[:,:,1]\n",
    "    \n",
    "    # Appling Thresholding on G_Chennel of RGB\n",
    "    g_binary = np.zeros_like(r_chennel)\n",
    "    g_binary[(g_chennel > 150) & (g_chennel <= 255)] = 1\n",
    "    \n",
    "    '''\n",
    "    luv_image = cv2.cvtColor(img,cv2.COLOR_RGB2LUV)\n",
    "    v_chennel = luv_image[:,:,2]\n",
    "    v_binary = np.zeros_like(v_chennel)\n",
    "    v_binary[(v_chennel > 150) & (v_chennel < 255)] = 1\n",
    "    '''\n",
    "    l_chennel = hls_img[:,:,1]\n",
    "    \n",
    "    # Appling Thresholding on S_Chennel of HLS\n",
    "    l_binary = np.zeros_like(l_chennel)\n",
    "    l_binary[(l_chennel > 50) & (l_chennel <= 255)] = 1\n",
    "    \n",
    "    # Mix Both Color Thresold and return Mixed color threshold\n",
    "    mixedColor = np.zeros_like(s_binary)\n",
    "    mixedColor[(r_binary == 1) & (s_binary == 1)] = 1\n",
    "    \n",
    "    return mixedColor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use All Threshold and combine all in one \n",
    "def Thresold(img):\n",
    "    absSobel = AbsSobelThresold(img,\"X\",(50,150),3)\n",
    "    meanSobel = MeanSobelThersold(img,(30,200),3)\n",
    "    dirSobel = DirThreshold(img,3,(np.pi/8, np.pi/2))\n",
    "    colorThrsold = ColorThresold(img,(230,255)) \n",
    "    combined = np.zeros_like(absSobel)\n",
    "    \n",
    "    #combined[((absSobel == 1)) | (colorThrsold == 1) ] = 1\n",
    "    combined[((absSobel == 1)) | (colorThrsold == 1) ] = 1\n",
    "    #plt.imshow(absSobel)\n",
    "    #plt.show()\n",
    "    #SideBySide(img,combined)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective Transformation \n",
    "   - Fn - PerspectiveT \n",
    "       - A perspective transform maps the points in a given image to different, desired, image points with a new perspective. The perspective transform you’ll be most interested in is a bird’s-eye view transform that let’s us view a lane from above; this will be useful for calculating the lane curvature later on. Aside from creating a bird’s eye view representation of an image, a perspective transform can also be used for all kinds of different view points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PerspectiveT(img):\n",
    "    ImgSize = (img.shape[1], img.shape[0])                                 # calculate hight and width of image\n",
    "\n",
    "    src = np.float32(                                                      # ROI Points (Src Points)\n",
    "        [[570, 470],\n",
    "         [200, 720],\n",
    "         [1110, 720],           \n",
    "         [722, 470]])\n",
    "    \n",
    "    dst = np.float32(                                                      # Points for perspective Transform (Des Point)\n",
    "        [[320, 0],\n",
    "        [320, 720],\n",
    "        [960, 720],\n",
    "        [960, 0]])\n",
    "\n",
    "    ######     Testing Code Start   ######\n",
    "    \n",
    "    a = [200,720]                                                             # To Display the ROI on Image\n",
    "    b = [1180,720]\n",
    "    c = [550,470] \n",
    "    d = [770,470]\n",
    "    pts = np.array([a,b,d,c])\n",
    "    \n",
    "    blackimg = np.zeros_like(img)\n",
    "    \n",
    "    mask=cv2.drawContours(blackimg,[pts],0,(255,255,255),-1)\n",
    "    new_test_img = cv2.bitwise_and(img,mask)\n",
    "    \n",
    "   ######     Testing Code End    ######\n",
    "    \n",
    "    m = cv2.getPerspectiveTransform(src, dst)                                        # Perspective Transformation \n",
    "    warped = cv2.warpPerspective(img, m, ImgSize, flags=cv2.INTER_LINEAR)            # Warp Image based on m\n",
    "    \n",
    "    M_inv= cv2.getPerspectiveTransform(dst, src)                                     # will be needed at the end to inverse again\n",
    "    return warped,M_inv,new_test_img                                                 # here new_test_img is only for debuging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window\n",
    "\n",
    " - Fn - SlidingWindow, fitPoly\n",
    "  - used for Sliding Windows and Fit a Polynomial\n",
    "  - it will find ind the Histogram \n",
    "  - se the two highest peaks from our histogram as a starting point for determining where the lane lines are, and then use sliding windows moving upward in the image (further along the road) to determine where the lane lines go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SlidingWindow(binary_warped):\n",
    "\n",
    "    #histogram = np.sum(2*binary_warped[binary_warped.shape[0]//3:,:], axis=0)      # Find the Histogram of bottom image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)      # Find the Histogram of bottom image\n",
    "    #plt.plot(histogram)\n",
    "    #plt.show()\n",
    "    # To Display Output\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255             \n",
    "    \n",
    "    # base left and right\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # HyperParameter\n",
    "    nwindow = 10\n",
    "    minpix = 100\n",
    "    margin = 70\n",
    "    height = np.int(binary_warped.shape[0]//nwindow)\n",
    "    \n",
    "    # NonZero in X & Y from Binary Image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    \n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # Rotate the loop for nwindow time \n",
    "    for window in range(nwindow):\n",
    "        \n",
    "        # calculate the Y points for rectangle\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*height\n",
    "        win_y_high = binary_warped.shape[0] - (window)*height\n",
    "        \n",
    "        # Calculate X points for rectangle\n",
    "        win_leftx_low = leftx_current - margin\n",
    "        win_leftx_high = leftx_current + margin                              \n",
    "        win_rightx_low = rightx_current - margin\n",
    "        win_rightx_high = rightx_current + margin\n",
    "        \n",
    "        # Draw Ractancgle\n",
    "        cv2.rectangle(out_img,(win_leftx_low,win_y_low),\n",
    "        (win_leftx_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_rightx_low,win_y_low),\n",
    "        (win_rightx_high,win_y_high),(255,0,0), 5) \n",
    "    \n",
    "        # Find out the nonzero points in ractangle box window\n",
    "        good_leftx_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_leftx_low) &  (nonzerox < win_leftx_high)).nonzero()[0] \n",
    "        good_rightx_inds = ((nonzerox >= win_rightx_low) & (nonzerox < win_rightx_high)\n",
    "                          & (nonzeroy >= win_y_low) & (nonzeroy < win_y_high)).nonzero()[0]\n",
    "        \n",
    "        # append this point in relevent side line\n",
    "        left_lane_inds.append(good_leftx_inds)\n",
    "        right_lane_inds.append(good_rightx_inds)\n",
    "        \n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(good_leftx_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_leftx_inds]))\n",
    "        if len(good_rightx_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_rightx_inds]))\n",
    "            \n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except TypeError:\n",
    "        pass\n",
    "    \n",
    "    # find out all nonzero points in lane_inds\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # fit the polynomial\n",
    "    left_fit_coef,right_fit_coef,leftx_fit,rightx_fit,ploty = fitPoly(binary_warped,leftx,lefty,rightx,righty)\n",
    "    visulize_img = None\n",
    "    #visulize_img = Visulization(out_img,leftx,lefty,rightx,righty,leftx_fit,rightx_fit,ploty)\n",
    "    \n",
    "    return visulize_img,left_fit_coef,right_fit_coef,left_lane_inds,right_lane_inds,ploty\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitPoly(binary_warped,leftx,lefty,rightx,righty):\n",
    "    \n",
    "    img_shape = (binary_warped.shape[1],binary_warped.shape[0])\n",
    "    \n",
    "    # find out the coef \n",
    "    left_fit_coef = np.polyfit(lefty,leftx,2)\n",
    "    right_fit_coef = np.polyfit(righty,rightx,2)\n",
    "    \n",
    "    \n",
    "    ploty = np.linspace(0,img_shape[1]-1,img_shape[1])\n",
    "    \n",
    "    # find out the leftx and rightx \n",
    "    leftx_fit = left_fit_coef[0]*ploty**2 + left_fit_coef[1]*ploty + left_fit_coef[2]\n",
    "    rightx_fit = right_fit_coef[0]*ploty**2 + right_fit_coef[1]*ploty + right_fit_coef[2]\n",
    "    \n",
    "    return left_fit_coef,right_fit_coef,leftx_fit,rightx_fit,ploty\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skiping the sliding windows step \n",
    "   - Fn -  NearSearch, DrawNearArea\n",
    "    - it will use the previous polynomial to skip the sliding window\n",
    "    - search in a margin around the previous lane line position\n",
    "    - This is equivalent to using a customized region of interest for each frame of video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NearSearch(binary_warped,left_fit_coef,right_fit_coef,ploty):\n",
    "    margin = 70\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    \n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzerox = nonzero[1]\n",
    "    nonzeroy = nonzero[0]\n",
    "    \n",
    "    #customized region of interest for each frame\n",
    "    left_lane_inds = ((nonzerox > (left_fit_coef[0]*(nonzeroy**2) + left_fit_coef[1]*(nonzeroy) + left_fit_coef[2] - margin)) &\n",
    "                     (nonzerox < (left_fit_coef[0]*(nonzeroy**2) + left_fit_coef[1]*(nonzeroy) + left_fit_coef[2] + margin)))\n",
    "                      \n",
    "    right_lane_inds = ((nonzerox > (right_fit_coef[0]*(nonzeroy**2) + right_fit_coef[1]*(nonzeroy) + right_fit_coef[2] - margin)) &\n",
    "                     (nonzerox < (right_fit_coef[0]*(nonzeroy**2) + right_fit_coef[1]*(nonzeroy) + right_fit_coef[2] + margin)))\n",
    "                      \n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "     \n",
    "    left_fit_coef,right_fit_coef,leftx_fit,rightx_fit,ploty = fitPoly(binary_warped,leftx,lefty,rightx,righty)\n",
    "    result = DrawNearArea(out_img,margin,nonzerox,nonzeroy,left_lane_inds,right_lane_inds,leftx_fit,rightx_fit,ploty)\n",
    "    #out_black_img = Visulization(out_img,leftx,lefty,rightx,righty,leftx_fit,rightx_fit,ploty)\n",
    "    return result,leftx_fit,rightx_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawNearArea(out_img,margin,nonzerox,nonzeroy,left_lane_inds,right_lane_inds,left_fitx,right_fitx,ploty):\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "   # plt.plot(left_fitx, ploty, color='yellow')\n",
    "   # plt.plot(right_fitx, ploty, color='yellow')\n",
    "    \n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    # Plot the polynomial lines onto the image\n",
    "\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Calibration\n",
    " -  Fn - CalibrateCamera \n",
    "  - This function is used to calibrate our camera  using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalibrateCamera():\n",
    "    nX = 9\n",
    "    nY = 6\n",
    "    \n",
    "    objPoints = []                                       # obj_points = to store the objectpoints ex:\n",
    "    imgPoints = []                                       # img_points = to store the imagepoints ex:\n",
    "    \n",
    "    objp = np.zeros((nX*nY,3), np.float32)               # create nX*nY size matrix having 0\n",
    "    objp[:,:2] = np.mgrid[0:nX,0:nY].T.reshape(-1,2)     #  (0,0,0),(1,0,0),(2,0,0),...,(9,6,0)\n",
    "    \n",
    "    \n",
    "    # from chessboard Images calibrate the camera \n",
    "    for calibImgName in os.listdir('./camera_cal'):\n",
    "        calibImg = cv2.imread(os.path.join('./camera_cal',calibImgName))\n",
    "        gray_calibImg = cv2.cvtColor(calibImg,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # find chessBoard Corners\n",
    "        ret,corners = cv2.findChessboardCorners(gray_calibImg,(nX,nY),None)\n",
    "        \n",
    "        if ret == True:\n",
    "            objPoints.append(objp)\n",
    "            imgPoints.append(corners)\n",
    "            calibImg = cv2.drawChessboardCorners(calibImg,(nX,nY),corners,ret)\n",
    "    \n",
    "    \n",
    "    ret,dist,mtx,rvecs,tvecs = cv2.calibrateCamera(objPoints,imgPoints,(calibImg.shape[1],calibImg.shape[0]),None,None)\n",
    "    \n",
    "    return dist,mtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undistortion\n",
    " -  Fn - UndistortImg \n",
    "  - This function is used to undistort Images.\n",
    "  - Image distortion occurs when a camera looks at 3D objects in the real world and transforms them into a 2D image; this transformation isn’t perfect. Distortion actually changes what the shape and size of these 3D objects appear to be. So, the first step in analyzing camera images, is to undo this distortion so that you can get correct and useful information out of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UndistortImg(img,mtx,dist):\n",
    "    undistorted_img = cv2.undistort(img,mtx,dist,None,mtx)                 # Undistort Image\n",
    "    return undistorted_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Curvature\n",
    " - Fn - RadiusOfCurv\n",
    " - located the lane line pixels, used their x and y pixel positions to fit a second order polynomial curve: f(y) = Ay^2 + By + C\n",
    " - for converting this from pixal space to real space use below conversions \n",
    "   1. ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "   2. xm_per_pix = 3.7/700 # meters per pixel in x dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RadiusOfCurv(img,x_values):\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    # If no pixels were found return None\n",
    "    y_points = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    y_eval = np.max(y_points)\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    #print((y_points*ym_per_pix).shape,(x_values*xm_per_pix).shape)\n",
    "    fit_cr = np.polyfit(y_points*ym_per_pix, x_values*xm_per_pix, 2)\n",
    "    curverad = ((1 + (2*fit_cr[0]*y_eval*ym_per_pix + fit_cr[1])**2)**1.5) / np.absolute(2*fit_cr[0])\n",
    "    return curverad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revert Perspective Transform \n",
    " - Fn - FinalImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FinalImage(img,warped,M_inv,leftx_fit,rightx_fit,new_test_img):\n",
    "    out_img = np.zeros_like(img)\n",
    "    y_points = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "\n",
    "    left_line_window = np.array(np.transpose(np.vstack([leftx_fit, y_points])))\n",
    "\n",
    "    right_line_window = np.array(np.flipud(np.transpose(np.vstack([rightx_fit, y_points]))))\n",
    "\n",
    "    line_points = np.vstack((left_line_window, right_line_window))\n",
    "\n",
    "    cv2.fillPoly(out_img, np.int_([line_points]), [0,255, 0])\n",
    "    \n",
    "    # Warping and drawing of lane boundaries on image as well as lane curvature information\n",
    "    unwarped = cv2.warpPerspective(out_img, M_inv, (img.shape[1],img.shape[0]) , flags=cv2.INTER_LINEAR)\n",
    "   # print(img.shape)\n",
    "   # print(img.dtype)\n",
    "   # print(unwarped.shape)\n",
    "   # print(unwarped.dtype)\n",
    "    result = cv2.addWeighted(img, 1, unwarped, 0.3,0)\n",
    "    #SideBySide(result,new_test_img)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Advance Pipeline \n",
    " - Fn - AdvancePipeline\n",
    " \n",
    "   1 . Camera calibration to remove lens distortion effects.\n",
    "   \n",
    "   2 . Image pre-processing to detect lane lines.\n",
    "   \n",
    "   3 . Perspective transform on road to aid in detection.\n",
    "   \n",
    "   4 . Lane Line Detection on transformed road.\n",
    "   \n",
    "   5 . Vehicle position and lane radius of curvature calculation.\n",
    "   \n",
    "   6 . Generate video of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdvancePipeline(img):\n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    \n",
    "    # Distortion removal on images\n",
    "    undistorted_img = UndistortImg(img,dist,mtx)\n",
    "\n",
    "    # Application of color and gradient thresholds to focus on lane lines\n",
    "    edgeBinary = Thresold(undistorted_img)\n",
    "\n",
    "    # Production of a bird’s eye view image via perspective transform\n",
    "    perspective_img,M_Inv,new_test_img = PerspectiveT(edgeBinary)\n",
    "    #plt.imshow(perspective_img)\n",
    "    #plt.show()\n",
    "    # Use of sliding windows to find hot lane line pixels\n",
    "    # Fitting of second degree polynomials to identify left and right lines composing the lane\n",
    "    visulize_img,left_fit_coef,right_fit_coef,left_lane_inds,right_lane_inds,ploty = SlidingWindow(perspective_img)\n",
    "    image,leftx_fit,rightx_fit = NearSearch(perspective_img,left_fit_coef,right_fit_coef,ploty)\n",
    "    #plt.imshow(image)\n",
    "    #plt.show()\n",
    "    # Computation of lane curvature and deviation from lane center\n",
    "    leftCurvRad = RadiusOfCurv(perspective_img,leftx_fit)\n",
    "    rightCurvRad = RadiusOfCurv(perspective_img,rightx_fit)\n",
    "    avgCurvRad = (leftCurvRad + rightCurvRad)/2\n",
    "    curvature_string = \"Radius of curvature: %.2f m\" % avgCurvRad\n",
    "    \n",
    "    # Warping and drawing of lane boundaries on image as well as lane curvature information\n",
    "    lane_center = (rightx_fit[718] + leftx_fit[178])/2\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    center_offset_pixels = abs(img_size[0]/2 - lane_center)\n",
    "    center_offset_mtrs = xm_per_pix*center_offset_pixels\n",
    "    offset_string = \"Center offset: %.2f m\" % center_offset_mtrs\n",
    "    result = FinalImage(img,perspective_img,M_Inv,leftx_fit,rightx_fit,new_test_img) # last arg remove\n",
    "    cv2.putText(result,curvature_string , (100, 90), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), thickness=3)\n",
    "    cv2.putText(result, offset_string, (100, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), thickness=3)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdvancePipelineIMG(img):\n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    \n",
    "    # Distortion removal on images\n",
    "    undistorted_img = UndistortImg(img,dist,mtx)\n",
    "\n",
    "    # Application of color and gradient thresholds to focus on lane lines\n",
    "    edgeBinary = Thresold(undistorted_img)\n",
    "\n",
    "    # Production of a bird’s eye view image via perspective transform\n",
    "    perspective_img,M_Inv,new_test_img = PerspectiveT(edgeBinary)\n",
    "    #plt.imshow(perspective_img)\n",
    "    #plt.show()\n",
    "    # Use of sliding windows to find hot lane line pixels\n",
    "    # Fitting of second degree polynomials to identify left and right lines composing the lane\n",
    "    visulize_img,left_fit_coef,right_fit_coef,left_lane_inds,right_lane_inds,ploty = SlidingWindow(perspective_img)\n",
    "    image,leftx_fit,rightx_fit = NearSearch(perspective_img,left_fit_coef,right_fit_coef,ploty)\n",
    "    #plt.imshow(image)\n",
    "    #plt.show()\n",
    "    # Computation of lane curvature and deviation from lane center\n",
    "    leftCurvRad = RadiusOfCurv(perspective_img,leftx_fit)\n",
    "    rightCurvRad = RadiusOfCurv(perspective_img,rightx_fit)\n",
    "    avgCurvRad = (leftCurvRad + rightCurvRad)/2\n",
    "    curvature_string = \"Radius of curvature: %.2f m\" % avgCurvRad\n",
    "    \n",
    "    # Warping and drawing of lane boundaries on image as well as lane curvature information\n",
    "    lane_center = (rightx_fit[718] + leftx_fit[178])/2\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    center_offset_pixels = abs(img_size[0]/2 - lane_center)\n",
    "    center_offset_mtrs = xm_per_pix*center_offset_pixels\n",
    "    offset_string = \"Center offset: %.2f m\" % center_offset_mtrs\n",
    "    result = FinalImage(img,perspective_img,M_Inv,leftx_fit,rightx_fit,new_test_img) # last arg remove\n",
    "    cv2.putText(result,curvature_string , (100, 90), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), thickness=3)\n",
    "    cv2.putText(result, offset_string, (100, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), thickness=3)\n",
    "    return undistorted_img,edgeBinary,perspective_img,image,result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing of AdvancePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation of camera calibration matrix and distortion coefficients from a set of chessboard images\n",
    "dist,mtx = CalibrateCamera()\n",
    "'''\n",
    "img = mpimg.imread(os.path.join('./test_images','real_test2.jpg'))\n",
    "result = AdvancePipeline(img)\n",
    "plt.imshow(result)\n",
    "plt.show()\n",
    "'''\n",
    "for imgName in os.listdir('./test_images'):\n",
    "    \n",
    "    img = mpimg.imread(os.path.join('./test_images',imgName))\n",
    "    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    if not os.path.exists(\"Warped_Op_Images\"):         \n",
    "        os.mkdir(\"Warped_Op_Images\")\n",
    "    undistorted_img,edgeBinary,perspective_img,image,result = AdvancePipelineIMG(img)\n",
    "    plt.imshow(perspective_img,cmap=\"gray\")\n",
    "    plt.show()\n",
    "    fig.savefig(\"Warped_Op_Images/\"+imgName)   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Testing  Video : project_video.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation of camera calibration matrix and distortion coefficients from a set of chessboard images\n",
    "dist,mtx = CalibrateCamera()\n",
    "\n",
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "video_output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(AdvancePipeline) \n",
    "%time white_clip.write_videofile(white_output, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation of camera calibration matrix and distortion coefficients from a set of chessboard images\n",
    "dist,mtx = CalibrateCamera()\n",
    "\n",
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "video_output = 'challenge_video.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(AdvancePipeline) \n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
