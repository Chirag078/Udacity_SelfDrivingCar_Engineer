{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Detection\n",
    "---\n",
    "#### Goal : \n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "---\n",
    "## [Rubric ](https://review.udacity.com/#!/rubrics/571/view) Points \n",
    "\n",
    "#### Here I will consider the rubric points individually and describe how I addressed each point in my implementation.  \n",
    "\n",
    "Writeup / README\n",
    "1. Provide a Writeup / README that includes all the rubric points and how you addressed each one. You can submit your writeup as markdown or pdf. Here is a template writeup for this project you can use as a guide and a starting point.\n",
    "You're reading it!\n",
    "---\n",
    "## Camera Calibration\n",
    "1. Briefly state how you computed the camera matrix and distortion coefficients. Provide an example of a distortion corrected calibration image.\n",
    "\n",
    "##### Steps :-\n",
    "- First i took the nX(number of corner in row) and nY(number of corner in column) to calibrate the camera\n",
    "- then i  prepared \"object points\", which will be the (x, y, z) coordinates of the chessboard corners in the world. Here I am assuming the chessboard is fixed on the (x, y) plane at z=0\n",
    "- After that i am searching for the corners in all chess board images and if corner is found then i am appending objp into objectpoints and corners into imagepoints\n",
    "- after this for conformation i am ploting the points again on images using corners which i got from previous step\n",
    "- I then used the output objpoints and imgpoints to compute the camera calibration and distortion coefficients using the cv2.calibrateCamera() function.\n",
    "\n",
    "![Calibration](https://github.com/Chirag078/Udacity_SelfDrivingCar_Engineer/blob/master/Project2_Advanced_Lane_Detection/examples/calib_image.JPG?raw=true)\n",
    "---\n",
    "\n",
    "## Advance Pipeline (Test Images)\n",
    "##### 1 . Distortion removal on images\n",
    "- Removed Distortion to the test image using camera calibration and distortion coefficients and  cv2.undistort() function.\n",
    "\n",
    "![Undistorted Image](https://github.com/Chirag078/Udacity_SelfDrivingCar_Engineer/blob/master/Project2_Advanced_Lane_Detection/Undistorted_Op_Images/test3.jpg?raw=true)\n",
    "\n",
    "##### 2 . Application of color and gradient thresholds to focus on lane lines \n",
    "- I used a combination of color and gradient thresholds to generate a binary image\n",
    "    Gradient & Color Threshold :\n",
    "    - Absolute Sobel in x direction \n",
    "    - R and S Channel as color Gradient\n",
    "\n",
    "![Threshold Image](https://github.com/Chirag078/Udacity_SelfDrivingCar_Engineer/blob/master/Project2_Advanced_Lane_Detection/Threshold_Op_Images/test3.jpg?raw=true)\n",
    "\n",
    "##### 3 . Production of a birdâ€™s eye view image via perspective transform\n",
    " - I verified that my perspective transform was working as expected by drawing the src and dst points onto a test image and its warped counterpart to verify that the lines appear parallel in the warped image.\n",
    "\n",
    "    src = np.float32(                                                    \n",
    "        [[570, 470],\n",
    "         [200, 720],\n",
    "         [1110, 720],           \n",
    "         [722, 470]])\n",
    "    \n",
    "    dst = np.float32(                                           \n",
    "        [[320, 0],\n",
    "        [320, 720],\n",
    "        [960, 720],\n",
    "        [960, 0]])\n",
    "\n",
    "![Warped Image](https://github.com/Chirag078/Udacity_SelfDrivingCar_Engineer/blob/master/Project2_Advanced_Lane_Detection/Warped_Op_Images/test3.jpg?raw=true)\n",
    "\t\t\n",
    "##### 4 . Fitting of second degree polynomials to identify left and right lines composing the lane\n",
    "- Using Histogram i found the peak Points which is starting points of the lane\n",
    "- then i used Sliding window concept on bird eye view image and applied second order polynomial\n",
    "\n",
    "![Warped Image](https://view5639f7e7.udacity-student-workspaces.com/files/CarND-Advanced-Lane-Lines/Window_Op_Images/test3.jpg)\n",
    "\n",
    "##### 5 . Computation of lane curvature and deviation from lane center\n",
    " - Calculated the curvature from the below equation\n",
    " \n",
    "![R_Curve](https://github.com/Chirag078/Udacity_SelfDrivingCar_Engineer/blob/master/Project2_Advanced_Lane_Detection/examples/Redius.JPG?raw=true) \n",
    "\n",
    "##### 6. Warping and drawing of lane boundaries on image as well as lane curvature information\n",
    " - here it my out put image with Warping and drawing of lane boundaries on image as well as lane curvature information\n",
    " \n",
    "![Final_Output](https://github.com/Chirag078/Udacity_SelfDrivingCar_Engineer/blob/master/Project2_Advanced_Lane_Detection/Final_Op_Images/test3.jpg?raw=true) \n",
    "\n",
    "---\n",
    "\n",
    "## Advance Pipeline (Project Video)\n",
    "\n",
    "[Lane Finding Project Video](https://classroom.udacity.com/nanodegrees/nd013/parts/168c60f1-cc92-450a-a91b-e427c326e6a7/modules/5d1efbaa-27d0-4ad5-a67a-48729ccebd9c/lessons/7cb63828-36aa-4cea-9239-700b5ea41f0b/concepts/0a96d23f-6c22-4053-a7f6-83e12ce5a6ec)\n",
    "\n",
    "---\n",
    "\n",
    "## Discussion\n",
    "\n",
    "\n",
    "#### Issue Which i Faced is listed below.\n",
    " -  it is like to consider to which thresold need to take is difficult. because if i am selecting r and s color chennal then it is working properly but in binary image it is not looking properly. but i tried with different color chennal and got the best out put for \"Project Video\" using r and s chennal selection \n",
    " \n",
    " - so now second issue is in sobel thresold value. here i used (50,150) as a thresold value so i am not able to load the challenge video but i changed this value and i succed to load that video and it that vido also i am getting some what clear output.\n",
    " \n",
    "#### Improvment\n",
    " - to make this algorithm robust we need to use Different color chennal and threshold combination. and need to select the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
